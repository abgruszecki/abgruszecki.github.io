<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Projects | ABG</title><link>https://abgru.me/project/</link><atom:link href="https://abgru.me/project/index.xml" rel="self" type="application/rss+xml"/><description>Projects</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 06 Aug 2025 00:00:00 +0000</lastBuildDate><image><url>https://abgru.me/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url><title>Projects</title><link>https://abgru.me/project/</link></image><item><title>Agnostics</title><link>https://abgru.me/project/agnostics/</link><pubDate>Wed, 06 Aug 2025 00:00:00 +0000</pubDate><guid>https://abgru.me/project/agnostics/</guid><description>&lt;p>Agnostics is a collaboration with
&lt;a href="https://ccs.neu.edu/~ytzi/" target="_blank" rel="noopener">Yangtian Zi&lt;/a>,
&lt;a href="https://aryawu0513.github.io/" target="_blank" rel="noopener">Zixuan Wu&lt;/a>,
Tejas Oberoi,
&lt;a href="https://canders1.github.io/" target="_blank" rel="noopener">Carolyn Jane Anderson&lt;/a>,
&lt;a href="https://www.cs.utexas.edu/people/faculty-researchers/joydeep-biswas" target="_blank" rel="noopener">Joydeep Biswas&lt;/a>,
and &lt;a href="https://ccs.neu.edu/~arjunguha/main/home/" target="_blank" rel="noopener">Arjun Guha&lt;/a>.&lt;/p>
&lt;p>LLMs excel at programming languages like Python and JavaScript,
yet stumble on low-resource languages essential to science and engineering.
Post-training the models is a bottleneck:
every new language seems to require new data, new tests,
and more reinforcement learning infrastructure.&lt;/p>
&lt;p>We show how to turn an existing dataset of coding problems into
a reinforcement learning environment which can be adapted to &lt;em>any&lt;/em> programming language.
Our approach turns Qwen 3 4B and 8B into SOTA ≤16B models for low-resource programming languages,
rivaling much larger models, including their 32B sibling.
And when we trained Qwen 3 4B on very low-resource programming languages,
the comparison wasn&amp;rsquo;t even fair.
(We&amp;rsquo;re comparing them on our multi-language version of LiveCodeBench,
which we&amp;rsquo;re releasing together with the report!)&lt;/p>
&lt;!--
Our training improves Qwen 3 4B's ability to code in low-resource programming languages
to the point where it rivals its 32B sibling, sometimes completely outclassing it.
-->
&lt;!-- This is technically a GFM table. -->
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./Table6.png" alt="Table 6 from the paper" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/th>
&lt;th style="text-align:center">
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./Table7.png" alt="Table 7 from the paper" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;/table>
&lt;h2 id="links">Links&lt;/h2>
&lt;p>An ArXiv report is available &lt;a href="https://arxiv.org/abs/2508.04865" target="_blank" rel="noopener">here&lt;/a>;
the most up-to-date version, with minor typos fixed, can be found &lt;a href="./agnostics.pdf">here&lt;/a>.&lt;/p>
&lt;p>Our trained models are available &lt;a href="https://huggingface.co/nuprl/agnostics" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;p>The script for evaluating models on Ag-LiveCodeBench-X can be found &lt;a href="https://github.com/nuprl/Ag-LiveCodeBench-X" target="_blank" rel="noopener">here&lt;/a>.
The dataset is available &lt;a href="https://huggingface.co/datasets/nuprl/Ag-LiveCodeBench-X" target="_blank" rel="noopener">here&lt;/a>,
and our verifiers are available &lt;a href="https://github.com/orgs/nuprl/packages/container/package/agnostics" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;p>We will also release our training framework after a formal publication!&lt;/p>
&lt;h2 id="brief-overview">Brief overview&lt;/h2>
&lt;p>Our key novel idea is to judge code &lt;em>only&lt;/em> by its externally observable behavior (e.g., I/O).
Some datasets are already in such a format, many others can be rewritten to it.
We can write a universal verifier for such problems, which lets us teach a model any programming language.
One universal verifier + a tiny per-language YAML file = reinforcement learning that works everywhere.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./Figure1.png" alt="Figure 1 from the paper" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>(1) We use an LLM to reformulate language-specific datasets into our standard language-agnostic format.
(2) We generate prompts and a configured verifier targeting a particular language,
with a small (often 4-line!) configuration.
(3) We apply reinforcement learning with verified rewards (RLVR) using a robust,
language-agnostic execution sandbox that we develop.
(4) The result is a model specialized to the target language.&lt;/p>
&lt;p>Our approach particularly excels at finetuning models for low-resource languages,
since it does not rely on language-specific high-quality datasets.&lt;/p>
&lt;p>An analysis of the generated programs shows that the trained models make fewer syntax and API mistakes.
The models have learned the simpler rules of the language,
which also reveals the algorithmic mistakes they make.
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./Figure6.png" alt="Figure 6 from the paper" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Find out more by reading the paper &lt;a href="./agnostics.pdf">here&lt;/a>!&lt;/p></description></item><item><title>Capture Tracking</title><link>https://abgru.me/project/capture-tracking/</link><pubDate>Mon, 15 Jan 2024 17:40:17 +0000</pubDate><guid>https://abgru.me/project/capture-tracking/</guid><description>&lt;p>Capture Tracking is an approach to tracking the capture of capabilities in types,
which has been the subject of a long collaboration with
Martin Odersky,
Jonathan Brachthäuser,
Ondřej Lhoták,
and Edward Lee,
and to which a number of other people have contributed.&lt;/p>
&lt;p>The foundational formal system for the approach is CC&amp;lt;:◻,
published in &lt;a href="https://dl.acm.org/doi/abs/10.1145/3618003" target="_blank" rel="noopener">TOPLAS&lt;/a>.
Its algorithmic aspects are discussed in a
&lt;a href="https://arxiv.org/abs/2306.06496" target="_blank" rel="noopener">technical report&lt;/a>.&lt;/p>
&lt;p>Martin Odersky&amp;rsquo;s Caprese project
is focused on investigating these formal foundations further
and developing their applications.
The particular questions include
(1) How to solve the &amp;ldquo;what color is your function&amp;rdquo; problem when mixing synchronous and asynchronous programming?
(2) How to express effect polymorphism without creating boilerplate?
(3) How to combine manual and automatic memory management?
(4) How to express high-level concurrency and parallelism, safely?
(5) How to migrate large existing code bases to the new system?
Find out in the slide deck &lt;a href="https://www.slideshare.net/Odersky/capabilities-for-resources-and-effects-252161040" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;p>CC&amp;lt;:◻ is neither the first nor the last formalism for Capture Tracking.
I discuss the developments that led to CC&amp;lt;:◻
in &lt;a href="https://infoscience.epfl.ch/record/309351?v=pdf" target="_blank" rel="noopener">my dissertation&lt;/a>
on the &amp;ldquo;Formal Foundations of Capture Tracking&amp;rdquo;.&lt;/p>
&lt;p>Capture Tracking is particularly focused on usability and ergonomics,
so naturally there is an implementation,
developed to first and foremost by Martin Odersky.
You can find out more on &lt;a href="https://docs.scala-lang.org/scala3/reference/experimental/cc.html" target="_blank" rel="noopener">this&lt;/a> page.&lt;/p>
&lt;p>Work progresses on developing CC&amp;lt;:◻ further.
A formal system which enriches it with safe concurrency
(by tracking separation of capabilities)
was conditionally accepted for OOPSLA 2024.
Find the preprint &lt;a href="https://arxiv.org/abs/2308.07474" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;p>There is also ongoing work on using the Capture Tracking implementation
to develop a base library for async computation in direct style.
A &amp;ldquo;strawman&amp;rdquo; version of this library is available in a Github repository
&lt;a href="https://github.com/lampepfl/gears" target="_blank" rel="noopener">here&lt;/a>.&lt;/p></description></item></channel></rss>