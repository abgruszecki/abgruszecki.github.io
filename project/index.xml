<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Projects | ABG</title><link>https://abgru.me/project/</link><atom:link href="https://abgru.me/project/index.xml" rel="self" type="application/rss+xml"/><description>Projects</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 06 Aug 2025 17:40:17 +0000</lastBuildDate><image><url>https://abgru.me/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url><title>Projects</title><link>https://abgru.me/project/</link></image><item><title>Agnostics</title><link>https://abgru.me/project/agnostics/</link><pubDate>Wed, 06 Aug 2025 17:40:17 +0000</pubDate><guid>https://abgru.me/project/agnostics/</guid><description>&lt;p>Agnostics is a collaboration with
Yangtian Zi,
Zixuan Wu,
Tejas Oberoi,
Carolyn Jane Anderson,
Joydeep Biswas,
and Arjun Guha.&lt;/p>
&lt;p>We show how to turn an existing dataset of coding problems into
a reinforcement learning environment which can be adapted to &lt;em>any&lt;/em> programming language.
Our training improves Qwen 3 4B ability to code in low-resource programming languages
to the point where it rivals its 32B sibling, sometimes completely outclassing it.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./Table1.png" alt="Table 1 from the paper" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h2 id="links">Links&lt;/h2>
&lt;p>An ArXiv report is due to be published today, August 6th 2025.
It can already be accessed &lt;a href="./agnostics.pdf">here&lt;/a>.&lt;/p>
&lt;p>Our trained models are available &lt;a href="https://huggingface.co/nuprl/agnostics" target="_blank" rel="noopener">here&lt;/a>.
The repository has tags named the same as the models from the paper.&lt;/p>
&lt;p>The script for evaluating models on Ag-LiveCodeBench-X can be found &lt;a href="https://github.com/nuprl/Ag-LiveCodeBench-X" target="_blank" rel="noopener">here&lt;/a>.
The associated dataset is available &lt;a href="https://huggingface.co/datasets/nuprl/Ag-LiveCodeBench-X" target="_blank" rel="noopener">here&lt;/a>,
and our containerized verifiers are available &lt;a href="https://github.com/orgs/nuprl/packages/container/package/agnostics" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;p>We will also release our training framework together with a formal publication!&lt;/p>
&lt;h2 id="brief-overview">Brief overview&lt;/h2>
&lt;p>Our key novel idea is to judge code &lt;em>only&lt;/em> by its externally observable behaviour (e.g., I/O).
Some existing datasets are already in such a format, many others can be rewritten to it.
We can write a universal verifier for such code, which lets us teach a model any programming language.
One universal verifier + a tiny YAML file per language = reinforcement learning that works everywhere.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./Figure1.png" alt="Figure 1 from the paper" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>(1) We use an LLM to reformulate language-specific datasets into our standard language-agnostic format.
(2) We generate prompts and a configured verifier targeting a particular language,
with a small (4-5 line) configuration.
(3) We apply reinforcement learning with verified rewards (RLVR) using a robust,
language-agnostic execution sandbox that we develop.
(4) The result is a model specialized to the target language.&lt;/p>
&lt;p>Our approach particularly excels at finetuning models for low-resource languages,
since it does not rely on language-specific high-quality datasets.&lt;/p>
&lt;p>An analysis of the generated programs shows that the trained models make fewer syntax and API mistakes.
The models have learned the simpler rules of the language,
which also reveals the algorithmic mistakes they make.
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./Figure6.png" alt="Figure 6 from the paper" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Find out more by reading the paper &lt;a href="./agnostics.pdf">here&lt;/a>!&lt;/p></description></item><item><title>Capture Tracking</title><link>https://abgru.me/project/capture-tracking/</link><pubDate>Mon, 15 Jan 2024 17:40:17 +0000</pubDate><guid>https://abgru.me/project/capture-tracking/</guid><description>&lt;p>Capture Tracking is an approach to tracking the capture of capabilities in types,
which has been the subject of a long collaboration with
Martin Odersky,
Jonathan Brachthäuser,
Ondřej Lhoták,
and Edward Lee,
and to which a number of other people have contributed.&lt;/p>
&lt;p>The foundational formal system for the approach is CC&amp;lt;:◻,
published in &lt;a href="https://dl.acm.org/doi/abs/10.1145/3618003" target="_blank" rel="noopener">TOPLAS&lt;/a>.
Its algorithmic aspects are discussed in a
&lt;a href="https://arxiv.org/abs/2306.06496" target="_blank" rel="noopener">technical report&lt;/a>.&lt;/p>
&lt;p>Martin Odersky&amp;rsquo;s Caprese project
is focused on investigating these formal foundations further
and developing their applications.
The particular questions include
(1) How to solve the &amp;ldquo;what color is your function&amp;rdquo; problem when mixing synchronous and asynchronous programming?
(2) How to express effect polymorphism without creating boilerplate?
(3) How to combine manual and automatic memory management?
(4) How to express high-level concurrency and parallelism, safely?
(5) How to migrate large existing code bases to the new system?
Find out in the slide deck &lt;a href="https://www.slideshare.net/Odersky/capabilities-for-resources-and-effects-252161040" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;p>CC&amp;lt;:◻ is neither the first nor the last formalism for Capture Tracking.
I discuss the developments that led to CC&amp;lt;:◻
in &lt;a href="https://infoscience.epfl.ch/record/309351?v=pdf" target="_blank" rel="noopener">my dissertation&lt;/a>
on the &amp;ldquo;Formal Foundations of Capture Tracking&amp;rdquo;.&lt;/p>
&lt;p>Capture Tracking is particularly focused on usability and ergonomics,
so naturally there is an implementation,
developed to first and foremost by Martin Odersky.
You can find out more on &lt;a href="https://docs.scala-lang.org/scala3/reference/experimental/cc.html" target="_blank" rel="noopener">this&lt;/a> page.&lt;/p>
&lt;p>Work progresses on developing CC&amp;lt;:◻ further.
A formal system which enriches it with safe concurrency
(by tracking separation of capabilities)
was conditionally accepted for OOPSLA 2024.
Find the preprint &lt;a href="https://arxiv.org/abs/2308.07474" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;p>There is also ongoing work on using the Capture Tracking implementation
to develop a base library for async computation in direct style.
A &amp;ldquo;strawman&amp;rdquo; version of this library is available in a Github repository
&lt;a href="https://github.com/lampepfl/gears" target="_blank" rel="noopener">here&lt;/a>.&lt;/p></description></item></channel></rss>