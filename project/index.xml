<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Projects | ABG</title><link>https://abgru.me/project/</link><atom:link href="https://abgru.me/project/index.xml" rel="self" type="application/rss+xml"/><description>Projects</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 06 Aug 2025 00:00:00 +0000</lastBuildDate><image><url>https://abgru.me/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url><title>Projects</title><link>https://abgru.me/project/</link></image><item><title>Agnostics</title><link>https://abgru.me/project/agnostics/</link><pubDate>Wed, 06 Aug 2025 00:00:00 +0000</pubDate><guid>https://abgru.me/project/agnostics/</guid><description>&lt;p>Agnostics is a collaboration with
&lt;a href="https://ccs.neu.edu/~ytzi/" target="_blank" rel="noopener">Yangtian Zi&lt;/a>,
&lt;a href="https://aryawu0513.github.io/" target="_blank" rel="noopener">Zixuan Wu&lt;/a>,
Tejas Oberoi,
&lt;a href="https://canders1.github.io/" target="_blank" rel="noopener">Carolyn Jane Anderson&lt;/a>,
&lt;a href="https://www.cs.utexas.edu/people/faculty-researchers/joydeep-biswas" target="_blank" rel="noopener">Joydeep Biswas&lt;/a>,
and &lt;a href="https://ccs.neu.edu/~arjunguha/main/home/" target="_blank" rel="noopener">Arjun Guha&lt;/a>.&lt;/p>
&lt;p>LLMs excel at programming languages like Python and JavaScript,
yet stumble on low-resource languages essential to science and engineering.
Post-training the models is a bottleneck:
every new language seems to require new data, new tests,
and more reinforcement learning infrastructure.&lt;/p>
&lt;p>We show how to turn an existing dataset of coding problems into
a reinforcement learning environment which can be adapted to &lt;em>any&lt;/em> programming language.
Our approach turns Qwen 3 4B and 8B into SOTA ≤16B models for low-resource programming languages,
rivaling much larger models, including their 32B sibling.
And when we trained Qwen 3 4B on very low-resource programming languages,
the comparison wasn&amp;rsquo;t even fair.
(We&amp;rsquo;re comparing them on our multi-language version of LiveCodeBench,
which we&amp;rsquo;re releasing together with the report!)&lt;/p>
&lt;!--
Our training improves Qwen 3 4B's ability to code in low-resource programming languages
to the point where it rivals its 32B sibling, sometimes completely outclassing it.
-->
&lt;!-- This is technically a GFM table. -->
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./Table6.png" alt="Table 6 from the paper" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/th>
&lt;th style="text-align:center">
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./Table7.png" alt="Table 7 from the paper" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;/table>
&lt;h2 id="links">Links&lt;/h2>
&lt;p>An ArXiv report is available &lt;a href="https://arxiv.org/abs/2508.04865" target="_blank" rel="noopener">here&lt;/a>;
the most up-to-date version, with minor typos fixed, can be found &lt;a href="./agnostics.pdf">here&lt;/a>.&lt;/p>
&lt;p>Our trained models are available &lt;a href="https://huggingface.co/nuprl/agnostics" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;p>The script for evaluating models on Ag-LiveCodeBench-X can be found &lt;a href="https://github.com/nuprl/Ag-LiveCodeBench-X" target="_blank" rel="noopener">here&lt;/a>.
The dataset is available &lt;a href="https://huggingface.co/datasets/nuprl/Ag-LiveCodeBench-X" target="_blank" rel="noopener">here&lt;/a>,
and our verifiers are available &lt;a href="https://github.com/orgs/nuprl/packages/container/package/agnostics" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;p>We will also release our training framework after a formal publication!&lt;/p>
&lt;h2 id="brief-overview">Brief overview&lt;/h2>
&lt;p>Our key novel idea is to judge code &lt;em>only&lt;/em> by its externally observable behavior (e.g., I/O).
Some datasets are already in such a format, many others can be rewritten to it.
We can write a universal verifier for such problems, which lets us teach a model any programming language.
One universal verifier + a tiny per-language YAML file = reinforcement learning that works everywhere.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./Figure1.png" alt="Figure 1 from the paper" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>(1) We use an LLM to reformulate language-specific datasets into our standard language-agnostic format.
(2) We generate prompts and a configured verifier targeting a particular language,
with a small (often 4-line!) configuration.
(3) We apply reinforcement learning with verified rewards (RLVR) using a robust,
language-agnostic execution sandbox that we develop.
(4) The result is a model specialized to the target language.&lt;/p>
&lt;p>Our approach particularly excels at finetuning models for low-resource languages,
since it does not rely on language-specific high-quality datasets.&lt;/p>
&lt;p>An analysis of the generated programs shows that the trained models make fewer syntax and API mistakes.
The models have learned the simpler rules of the language,
which also reveals the algorithmic mistakes they make.
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./Figure6.png" alt="Figure 6 from the paper" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Find out more by reading the paper &lt;a href="./agnostics.pdf">here&lt;/a>!&lt;/p></description></item><item><title>Capture Tracking</title><link>https://abgru.me/project/capture-tracking/</link><pubDate>Mon, 15 Jan 2024 17:40:17 +0000</pubDate><guid>https://abgru.me/project/capture-tracking/</guid><description>&lt;p>Capture Tracking uses object capabilities tracked in types to unify effect and resource ownership systems.
It was the main topic of my PhD and a subject of a long collaboration with
&lt;a href="https://people.epfl.ch/martin.odersky?lang=en" target="_blank" rel="noopener">Martin Odersky&lt;/a>,
&lt;a href="https://se.informatik.uni-tuebingen.de/team/brachthaeuser/" target="_blank" rel="noopener">Jonathan Brachthäuser&lt;/a>,
&lt;a href="https://plg.uwaterloo.ca/~olhotak/" target="_blank" rel="noopener">Ondřej Lhoták&lt;/a>,
and Edward Lee.
A number of other people have contributed to the project,
including &lt;a href="https://www.yichenxu.me/" target="_blank" rel="noopener">Yichen Xu&lt;/a>
and
&lt;a href="https://bracevac.org/" target="_blank" rel="noopener">Oliver Bračevac&lt;/a>.&lt;/p>
&lt;p>I&amp;rsquo;m no longer directly involved in the effort.
For more up-to-date information, try the &lt;a href="https://capless.cc/" target="_blank" rel="noopener">Capture Checking&lt;/a> website.
Oliver Bračevac&amp;rsquo;s
&lt;a href="https://bracevac.org/assets/pdf/scaladays2025_annot.pdf" target="_blank" rel="noopener">Scala Days 2025 presentation&lt;/a>
also shows a number of more recent developments in detail.&lt;/p>
&lt;p>My contributions,
presented in &lt;a href="https://infoscience.epfl.ch/record/309351?v=pdf" target="_blank" rel="noopener">my thesis&lt;/a>,
were centered around the formal foundations for the approach.
The foundational formal system I was involved with is CC&amp;lt;:◻,
published in &lt;a href="https://dl.acm.org/doi/abs/10.1145/3618003" target="_blank" rel="noopener">TOPLAS 2023&lt;/a>.
My thesis also discusses other developments which led to CC&amp;lt;:◻.&lt;/p>
&lt;p>I also proposed Gradient,
a Scala extension for gradually securing and compartmentalizing existing applications
via object capabilities tracked in types.
The associated paper was published at &lt;a href="https://dl.acm.org/doi/10.1145/3689751" target="_blank" rel="noopener">OOPSLA 2024&lt;/a>;
the &lt;a href="https://www.youtube.com/watch?v=5BcldnDr4kY" target="_blank" rel="noopener">OOPSLA presentation&lt;/a> gives an accessible overview.&lt;/p>
&lt;p>An algorithmic version of CC&amp;lt;:◻ is discussed in a &lt;a href="https://arxiv.org/abs/2306.06496" target="_blank" rel="noopener">technical report&lt;/a>.&lt;/p>
&lt;p>By the time I wrote my thesis, the Scala implementation was developed first and foremost by Martin Odersky.
See the official documentation &lt;a href="https://docs.scala-lang.org/scala3/reference/experimental/cc.html" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;p>The implementation was extended with a number of features since my thesis, which led to System Capless,
an updated formal foundation for the system published at &lt;a href="https://dl.acm.org/doi/abs/10.1145/3763112" target="_blank" rel="noopener">OOPSLA 2025&lt;/a>.&lt;/p>
&lt;p>System Capybara extends Capture Tracking with safe concurrency features,
as presented on its &lt;a href="https://capless.cc/#/project/system-capybara" target="_blank" rel="noopener">project page&lt;/a>.
A formal system from which System Capybara evolved was published at &lt;a href="https://dl.acm.org/doi/abs/10.1145/3649853" target="_blank" rel="noopener">OOPSLA 2024&lt;/a>.&lt;/p>
&lt;p>Gears is an ongoing project to extend Scala with structured async computation in direct style,
with one-shot continuations as a primitive.
See the project website &lt;a href="https://lampepfl.github.io/gears/" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;p>Martin Odersky&amp;rsquo;s ongoing Caprese project aims to further develop both the formal foundations
and the practical applications of Capture Tracking.
The particular questions include
(1) How to solve the &amp;ldquo;what color is your function&amp;rdquo; problem when mixing synchronous and asynchronous programming?
(2) How to express effect polymorphism without creating boilerplate?
(3) How to combine manual and automatic memory management?
(4) How to express high-level concurrency and parallelism, safely?
(5) How to migrate large existing code bases to the new system?
See the slide deck &lt;a href="https://www.slideshare.net/Odersky/capabilities-for-resources-and-effects-252161040" target="_blank" rel="noopener">here&lt;/a>.&lt;/p></description></item></channel></rss>